<!DOCTYPE html><html lang="en"><head>
	<meta name="generator" content="Hugo 0.147.8">
    <meta charset="utf-8">
<title>SKE &amp; SKI: Theory and Methods</title>
<meta name="description" content="Symbolic Knowledge Extraction and Injection: Theory and Methods">

<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no"><link rel="stylesheet" href="/talk-2025-woa-nesy/reveal-js/dist/reset.css">
<link rel="stylesheet" href="/talk-2025-woa-nesy/reveal-js/dist/reveal.css">
  <link rel="stylesheet" href="/talk-2025-woa-nesy/css/custom-theme.min.ed5bfd9e406c86e5ecba1c75d54dcd092e7ef3029e200b559a53bcd987fb2844.css" id="theme"><link rel="stylesheet" href="/talk-2025-woa-nesy/highlight-js/solarized-dark.min.css">
<link href="https://fonts.googleapis.com/css?family=Roboto Mono" rel="stylesheet">
<link href="https://fonts.googleapis.com/css?family=Oxygen Mono" rel="stylesheet">
<link href="https://fonts.googleapis.com/css?family=Ubuntu Mono" rel="stylesheet">
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-4bw+/aepP/YC94hEpVNVgiZdgIC5+VKNBQNGCHeKRQN+PtmoHDEXuppvnDJzQIu9" crossorigin="anonymous">
<link href="https://cdn.jsdelivr.net/gh/DanySK/css-blur-animation/blur.css" rel="stylesheet" crossorigin="anonymous">

<script src="https://kit.fontawesome.com/81ac037be0.js" crossorigin="anonymous"></script>
<script type="text/javascript" src="https://unpkg.com/qr-code-styling@1.5.0/lib/qr-code-styling.js"></script>

  </head>
  <body>
    
    <div class="reveal">
      <div class="slides">
  

    <section>

<section data-shortcode-section="">
<h1 id="symbolic-knowledge-extraction-and-injectiontheory-and-methods">Symbolic Knowledge Extraction and Injection:<br>Theory and Methods</h1>
<p><a href="mailto:giovanni.ciatto@unibo.it">Giovanni Ciatto</a> and <a href="mailto:matteo.magnini@unibo.it">Matteo Magnini</a>
<br>Dipartimento di Informatica — Scienza e Ingegneria (DISI), Sede di Cesena,
<br> Alma Mater Studiorum—Università di Bologna</p>
<p><span class="hint">(last built on: 2025-06-16)</span></p>
</section><section>
<h2 id="link-to-these-slides">Link to these slides</h2>
<p><a href="https://MatteoMagnini.github.io/talk-2025-woa-nesy/">https://MatteoMagnini.github.io/talk-2025-woa-nesy/</a></p>
<div id="MzM5NGIyYmJjZTE4MjZlMDhhM2YxYmVkOTMyYmYwOGI4YTRlMzRjMWVjMTNiZDdhNDc2Yjk1ZWQwMDMzYjk5Yw==" style=""></div>
<script type="text/javascript">
    const qrCode = new QRCodeStyling({
        width:  300 ,
        height:  300 ,
        type: "svg",
        data: "https://MatteoMagnini.github.io/talk-2025-woa-nesy/",
        image: "https://upload.wikimedia.org/wikipedia/commons/9/91/Octicons-mark-github.svg",
        dotsOptions: {
            color: "#000000",
            type: "rounded"
        },
        backgroundOptions: {
            color: "#ffffff",
        },
        imageOptions: {
            crossOrigin: "anonymous",
            margin:  10 
        }
    });
    qrCode.append(document.getElementById("MzM5NGIyYmJjZTE4MjZlMDhhM2YxYmVkOTMyYmYwOGI4YTRlMzRjMWVjMTNiZDdhNDc2Yjk1ZWQwMDMzYjk5Yw=="));
</script>
<p><a href="?print-pdf&amp;pdfSeparateFragments=false"><i class="fa fa-print" aria-hidden="true"></i> printable version</a></p>

</section>
</section>

<section data-noprocess="" data-shortcode-slide="" id="background">
  
<h1 id="background">Background</h1>
<p>Quick overview on symbolic vs. sub-symbolic AI</p>
</section><section>
<h2 id="overview-on-ai">Overview on AI</h2>






<img src="./images/ai-map.svg" alt="AI map" style="width: 100%; max-width: 95vw; max-height: 80vh; object-fit: contain; ">

<ul>
<li>wide field of research, with many <em>sub-fields</em></li>
<li>each sub-field has its own relevant <em>tasks</em> (problems) …</li>
<li>… and each task comes with many useful <em>methods</em> (algorithms)</li>
</ul>
</section><section>
<h2 id="symbolic-vs-sub-symbolic-ai">Symbolic vs. Sub-symbolic AI</h2>
<p>Two broad categories of AI approaches:</p>






<img src="./images/ai-map2.svg" alt="AI map with a focus on symbolic vs sub-symbolic" style="width: 100%; max-width: 95vw; max-height: 80vh; object-fit: contain; ">

</section><section>


<section data-shortcode-section="">
<h2 id="examples-of-symbolic-ai-pt-1">Examples of Symbolic AI (pt. 1)</h2>
<ul>
<li><strong>Logic programming</strong>: SLD resolution (e.g., Prolog)</li>
<li><strong>Knowledge representation</strong>: Semantic Web (e.g., OWL), Description Logics (e.g., ALC)</li>
<li><strong>Automated reasoning</strong>: Theorem proving, Model checking</li>
<li><strong>Planning</strong>: STRIPS, PDDL</li>
</ul>
</section><section>
<h2 id="examples-of-symbolic-ai-pt-2">Examples of Symbolic AI (pt. 2)</h2>
<h3 id="logic-programming-with-sld-resolution">Logic programming with SLD resolution</h3>
<img src="./images/proof-tree.png" alt="Example of SLD resolution on a simple theory" style="width: 100%; max-width: 95vw; max-height: 60vh; object-fit: contain; ">
</section><section>
<h2 id="examples-of-symbolic-ai-pt-3">Examples of Symbolic AI (pt. 3)</h2>
<h3 id="ontology-definition-in-owl">Ontology definition in OWL</h3>
<img src="./images/ontology-example.png" alt="Example of ontology definition in OWL" style="width: 80%; max-width: 95vw; max-height: 60vh; object-fit: contain; ">
</section><section>
<h2 id="examples-of-symbolic-ai-pt-4">Examples of Symbolic AI (pt. 4)</h2>
<h3 id="model-checking-as-opposed-to-testing">Model-checking (as opposed to testing)</h3>
<img src="./images/model-checking-vs-testing.webp" alt="Main differences among model-checking and testing for verifying computational systems" style="width: 80%; max-width: 95vw; max-height: 60vh; object-fit: contain; ">
</section><section>
<h2 id="examples-of-symbolic-ai-pt-5">Examples of Symbolic AI (pt. 5)</h2>
<h3 id="planning-in-strips">Planning in STRIPS</h3>
<div class="container w-100 m-0 p-0">
    <div class="row "><div class="col "><img src="./images/planning.png" alt="Example of start vs goal state + state branching" style="width: 100%; max-width: 95vw; max-height: 60vh; object-fit: contain; ">
</div>
<div class="col "><br>
<h4 id="available-actions">Available actions</h4>
<ul>
<li><code>grab(X)</code>: grabs block <code>X</code> from the table</li>
<li><code>put(X)</code>: puts block <code>X</code> on the table</li>
<li><code>stack(X, Y)</code>: stacks block <code>X</code> on top of block <code>Y</code></li>
<li><code>unstack(X, Y)</code>: un-stacks block <code>X</code> from block <code>Y</code></li>
</ul>
</div>
</div>
</div>

</section>
</section><section>
<h2 id="what-do-these-symbolic-approaches-have-in-common">What do these <em>symbolic</em> approaches have in common?</h2>
<ul>
<li>
<p><strong>Structured representations</strong>: knowledge (I/O data) is represented in a structured, formal way (e.g., logic formulas, ontologies)</p>
</li>
<li>
<p><strong>Algorithmic manipulation of representations</strong>: each approach relies on algorithms that manipulate these structured representations following exact rules</p>
</li>
<li>
<p><strong>Crisp semantics</strong>: the meaning of the representations is well-defined, and the algorithms produce exact results</p>
<ul>
<li>representations are either <em>well-formed or not</em>, algorithms rely on rules which are either <em>applicable or not</em></li>
</ul>
</li>
<li>
<p><strong>Model-driven</strong>: algorithms may commonly work in zero- or few-shot settings, humans must commonly model and encode knowledge in the target structure</p>
</li>
<li>
<p><strong>Clear computational complexity</strong>: the decidability, complexity, and tractability of the algorithms are well understood</p>
</li>
</ul>
</section><section>


<section data-shortcode-section="">
<h2 id="examples-of-sub-symbolic-ai-pt-1">Examples of Sub-symbolic AI (pt. 1)</h2>
<ul>
<li>
<p><strong>Machine learning</strong>: supervised, unsupervised, and reinforcement learning</p>
<ul>
<li><em>Supervised</em> learning: fitting a discrete (classification) or a continuous function (regression) from examples</li>
<li><em>Unsupervised</em> learning: clustering, dimensionality reduction</li>
<li><em>Reinforcement</em> learning: learning a policy to maximize a reward signal, via simulation</li>
</ul>
</li>
<li>
<p><strong>Probabilistic reasoning</strong>: Bayesian networks, Markov models, probabilistic logic programming</p>
</li>
</ul>
</section><section>
<h2 id="examples-of-sub-symbolic-ai-pt-2">Examples of Sub-symbolic AI (pt. 2)</h2>
<h3 id="supervised-learning">Supervised learning</h3>
<img src="./images/supervised.png" alt="Overview on the supervised learning process" style="width: 100%; max-width: 95vw; max-height: 60vh; object-fit: contain; ">
</section><section>
<h2 id="examples-of-sub-symbolic-ai-pt-3">Examples of Sub-symbolic AI (pt. 3)</h2>
<h3 id="supervised-learning--classification-vs-regression-12">Supervised learning – Classification vs. Regression (1/2)</h3>
<p>Data separation vs. curve fitting:</p>
<img src="./images/classification-vs-regression1.png" alt="Classification vs. Regression: separation vs. curve fitting" style="width: 100%; max-width: 95vw; max-height: 60vh; object-fit: contain; ">
</section><section>
<h2 id="examples-of-sub-symbolic-ai-pt-4">Examples of Sub-symbolic AI (pt. 4)</h2>
<h3 id="supervised-learning--classification-vs-regression-22">Supervised learning – Classification vs. Regression (2/2)</h3>
<p>Focus on the target feature:</p>
<img src="./images/classification-vs-regression2.png" alt="Classification vs. Regression: finite vs. continuous target feature" style="width: 100%; max-width: 95vw; max-height: 60vh; object-fit: contain; ">
</section><section>
<h2 id="examples-of-sub-symbolic-ai-pt-5">Examples of Sub-symbolic AI (pt. 5)</h2>
<h3 id="unsupervised-learning--clustering">Unsupervised learning – Clustering</h3>
<img src="./images/clustering.png" alt="Example of the clustering task" style="width: 100%; max-width: 95vw; max-height: 60vh; object-fit: contain; ">
</section><section>
<h2 id="examples-of-sub-symbolic-ai-pt-6">Examples of Sub-symbolic AI (pt. 6)</h2>
<h3 id="unsupervised-learning--reinforcement-learning-metaphor">Unsupervised learning – Reinforcement learning (metaphor)</h3>
<img src="./images/reinforcement.svg" alt="Main idea behind reinforcement learning" style="width: 100%; max-width: 95vw; max-height: 60vh; object-fit: contain; ">
</section><section>
<h2 id="examples-of-sub-symbolic-ai-pt-7">Examples of Sub-symbolic AI (pt. 7)</h2>
<h3 id="reinforcement-learning--reinforcement-learning-policy">Reinforcement learning – Reinforcement learning (policy)</h3>
<img src="./images/q-table.png" alt="The goal of reinforcement learning is to estimate a policy, i.e. a function (e.g. a table) estimating the expected reward per each state–action pair" style="width: 100%; max-width: 95vw; max-height: 60vh; object-fit: contain; ">

</section>
</section><section>
<h2 id="what-do-these-sub-symbolic-approaches-have-in-common">What do these <em>sub-symbolic</em> approaches have in common?</h2>
<ul>
<li>
<p><strong>Numeric representations</strong>: knowledge (I/O data) is represented in a less structured way, often as vectors/matrices/tensors of numbers</p>
</li>
<li>
<p><strong>Differentiable manipulation of representations</strong>: algorithms rely on mathematical operations involving these numeric representations, most-commonly undergoing some optimization process</p>
<ul>
<li>e.g., sum, product, max, min, etc.</li>
</ul>
</li>
<li>
<p><strong>Fuzzy/continuous semantics</strong>: representations are from continuous spaces, where similarities and distances are defined in a continuous way, and algorithms may yield fuzzy results</p>
</li>
<li>
<p><strong>Data-driven</strong> + <strong>Usage vs. training</strong>: algorithms are often trained on data, to be later re-used on other data</p>
<ul>
<li>usage is commonly impractical or impossible without training</li>
</ul>
</li>
<li>
<p><strong>Unclear computational complexity</strong>: strong reliance on greedy or time-limited optimization methods, lack of theoretical guarantees on the quality of the results</p>
</li>
</ul>
</section><section>


<section data-shortcode-section="">
<h2 id="why-the-wording-symbolic-vs-sub-symbolic-pt-1">Why the wording “Symbolic” vs. “Sub-symbolic”? (pt. 1)</h2>
<h3 id="local-vs-distributed-representations">Local vs. Distributed Representations</h3>
<div class="container w-100 m-0 p-0">
    <div class="row "><div class="col "><img src="./images/local-distributed-representations.png" alt="Local vs. Distributed Representations of a bunch of animals" style="width: 100%; max-width: 95vw; max-height: 60vh; object-fit: contain; ">
</div>
<div class="col "><br>
<ul>
<li>
<p><strong>Local</strong> $\approx$ “symbolic”: each symbol has a clear, distinct meaning</p>
<ul>
<li>e.g. <code>"bear"</code> is a symbol denoting a crisp category (either the animal is a bear or not)</li>
</ul>
</li>
<li>
<p><strong>Distributed</strong> $\approx$ “non-symbolic”: symbols do not have a clear meaning per se, but the whole representation does</p>
<ul>
<li>e.g. <code>"swim"</code> is fuzzy capability: one animal may be (un)able to swim to some extent</li>
</ul>
</li>
</ul>
<br>
<span class="fragment ">
  <blockquote>
<p>Let’s say we need to represent $N$ classes, how many columns would the tables have?</p></blockquote>
</span>
</div>
</div>
</div>
</section><section>
<h2 id="why-the-wording-symbolic-vs-sub-symbolic-pt-2">Why the wording “Symbolic” vs. “Sub-symbolic”? (pt. 2)</h2>
<h3 id="what-is-a-symbol-after-all-arent-numbers-symbols-too">What is a “symbol” after all? Aren’t numbers symbols too?</h3>
<p>According to <a href="https://doi.org/10.1007/978-3-642-76070-9_6">Tim van Gelder in 1990</a>:</p>
<blockquote>
<p><strong>Symbolic</strong> representations of knowledge</p>
<ul>
<li>involve a <em>set of symbols</em></li>
<li>which can be <em>combined</em> (e.g., concatenated) in (possibly) infinitely many ways,</li>
<li>following precise <em>syntactical rules</em>,</li>
<li>where both elementary symbols and any admissible combination of them can be <em>assigned with meaning</em></li>
</ul></blockquote>
</section><section>
<h2 id="why-sub-symbolic-instead-of-non-symbolic-or-just-numerical">Why “<em>Sub</em>-symbolic” instead of “Non-symbolic” or just “Numerical”?</h2>
<ul>
<li>
<p>There exist approaches where symbols are combined with numbers, e.g.:</p>
<ul>
<li><strong>Probabilistic logic programming</strong>: where logic statements are combined with probabilities</li>
<li><strong>Fuzzy logic</strong>: where logic statements are combined with degrees of truth</li>
<li><strong>Bayesian networks</strong>: a.k.a. graphical models, where nodes are symbols and edges are conditional dependencies with probabilities, e.g.
<img src="./images/bn.png" alt="Example of a Bayesian network"></li>
</ul>
</li>
<li>
<p>These approaches are <em>not purely symbolic</em>, but they are <em>not purely numeric</em> either, so we call the overall category <strong>“sub-symbolic”</strong></p>
</li>
</ul>

</section>
</section>

  


</div>
      

    </div>
<script type="text/javascript" src="/talk-2025-woa-nesy/reveal-hugo/object-assign.js"></script>

<a href="/talk-2025-woa-nesy/reveal-js/dist/print/" id="print-location" style="display: none;"></a>

<script type="application/json" id="reveal-hugo-site-params">{"custom_theme":"custom-theme.scss","custom_theme_compile":true,"custom_theme_options":{"enablesourcemap":true,"targetpath":"css/custom-theme.css"},"height":"1080","highlight_theme":"solarized-dark","history":true,"mermaid":[{}],"slide_number":true,"theme":"league","transition":"slide","transition_speed":"fast","width":"1920"}</script>
<script type="application/json" id="reveal-hugo-page-params">null</script>

<script src="/talk-2025-woa-nesy/reveal-js/dist/reveal.js"></script>


  
  
  <script type="text/javascript" src="/talk-2025-woa-nesy/reveal-js/plugin/markdown/markdown.js"></script>
  
  <script type="text/javascript" src="/talk-2025-woa-nesy/reveal-js/plugin/highlight/highlight.js"></script>
  
  <script type="text/javascript" src="/talk-2025-woa-nesy/reveal-js/plugin/zoom/zoom.js"></script>
  
  <script type="text/javascript" src="/talk-2025-woa-nesy/reveal-js/plugin/notes/notes.js"></script>
  
  
  <script type="text/javascript" src="/talk-2025-woa-nesy/reveal-js/plugin/notes/notes.js"></script>




<script type="text/javascript">
  
  
  function camelize(map) {
    if (map) {
      Object.keys(map).forEach(function(k) {
        newK = k.replace(/(\_\w)/g, function(m) { return m[1].toUpperCase() });
        if (newK != k) {
          map[newK] = map[k];
          delete map[k];
        }
      });
    }
    return map;
  }

  var revealHugoDefaults = { center: true, controls: true, history: true, progress: true, transition: "slide" };

  var revealHugoPlugins = {
    plugins: [ RevealMarkdown, RevealHighlight, RevealNotes, RevealZoom ]
   };
  var revealHugoSiteParams = JSON.parse(document.getElementById('reveal-hugo-site-params').innerHTML);
  var revealHugoPageParams = JSON.parse(document.getElementById('reveal-hugo-page-params').innerHTML);
  
  var options = Object.assign({},
    camelize(revealHugoDefaults),
    camelize(revealHugoSiteParams),
    camelize(revealHugoPageParams),
    camelize(revealHugoPlugins));
  Reveal.initialize(options);
</script>







  
  

  
  

  
  





    <script>
    MathJax = {
      tex: {
        inlineMath: [['$', '$'], ['\\(', '\\)']]
      },
      svg: {
        fontCache: 'global'
      }
    };
</script>

<script type="text/javascript" id="MathJax-script" async="" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-svg.js">
</script>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.1/dist/js/bootstrap.bundle.min.js" integrity="sha384-HwwvtgBNo3bZJJLYd8oVXjrBZt8cqVSpeBNS5n7C8IVInixGAoxmnlMuBnhbgrkm" crossorigin="anonymous"></script>

<script>
  if (/.*?(\?|&)print-pdf/.test(window.location.toString())) {
      var ytVideos = document.getElementsByTagName("iframe")
      for (let i = 0; i < ytVideos.length; i++) {
          var videoFrame = ytVideos[i]
          var isYouTube = /^https?:\/\/(www.)youtube\.com\/.*/.test(videoFrame.src)
          if (isYouTube) {
              console.log(`Removing ${videoFrame.src}`)
              var parent = videoFrame.parentElement
              videoFrame.remove()
              var p = document.createElement('p')
              p.append(
                  document.createTextNode(
                      "There was an embedded video here, but it is disabled in the printed version of the slides."
                  )
              )
              p.append(document.createElement('br'))
              p.append(
                  document.createTextNode(
                      `Visit instead ${
                          videoFrame.src
                      } or ${
                          videoFrame.src.replace(
                              /(^https?:\/\/(www.)youtube\.com)\/(embed\/)(\w+).*/,
                              "https://www.youtube.com/watch?v=$4"
                          )
                      }`
                  )
              )
              parent.appendChild(p)
          }
      }
  }
</script>


    
  

</body></html>